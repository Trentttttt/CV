{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Abstract and Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this document is to introduce the central tradeoff in supervised learning theory: The bias-variance tradeoff. We introduce a unified generalization error framework for both regression and classification. The training-validation-testing triplet framework has been presented for model selection and generalization error estimation. We also discuss an alternative approach of cross-validation to fine-tune model parameters. We decompose the generalization error of a supervised learning model into bias, variance, and noise so as to crystalize the bias-variance tradeoff and the relationship between model complexity and prediction errors. Regularization techniques will also be introduced to address overfitting. The learning theory, modeling details, the case study, and the Python code are included in this document. \n",
    "\n",
    "Below is the outline of this document:\n",
    "\n",
    "- In [Section 1](#section_1), we discuss supervised learning in a unified framework.\n",
    "\n",
    "- In [Section 2](#section_2), we introduce the train-validate-test triplet and apply it to the Kwai user retention prediction case.\n",
    "\n",
    "- In [Section 3](#section_3), we introduce $k-$fold cross validation and apply it to the Kwai user retention prediction case.\n",
    "\n",
    "- In [Section 4](#section_4), we present the bias-variance tradeoff and introduce the regularization method (such as lasso and ridge regressions) to address overfitting. The boston housing prediction problem is also discussed as a demonstration for lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "# 1. Supervised Learning in a Unified Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us recall a general form of supervised learning. We have a sample data set, $\\mathcal D:=\\{Y_i,X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$, to train a model (a regressor or a classifier) $\\hat f(\\cdot)$. For a regression problem, the outcome variable $Y_i$ is continuous; for a classification problem, the outcome $Y_i$ is discrete.\n",
    "\n",
    "The sample data $\\mathcal D$ should come from a broader population and we hope that the sample could reasonably represent the entire population. For example, the sample data may come from a well-designed survey with which we could understand the whole population well. Mathematically, we are assuming that both the sample data $\\mathcal D$ and the population data are the **SAME** probablistic data generating process/distribution. Therefore, we could extract information from the sample data to reason about the data generating process and the whole population. This rationale is called **generalization** in supervised learning.\n",
    "\n",
    "For this document, let us consider the following supervised learning problem:\n",
    "\n",
    "----------\n",
    "\n",
    "<font color=red>\n",
    "    \n",
    "- **Input:** A sample training data set $\\mathcal D:=\\{Y_i,X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$. Here, the outcome variable $Y$ could be either discrete or continuous\n",
    "- **Output:** A model fitted on $\\mathcal D$ such that the **generalization error** $\\mathbb E[\\mathcal L(Y,\\hat f(X))]$ is **minimized**, where $\\mathcal L(\\cdot,\\cdot)$ is the loss/error function for the problem of interest and the expectation is taken with respect to the \"true\" distribution that generates the sample data and the population data. In most cases, the loss function $\\mathcal L(Y,\\hat f(X))$ takes the forms of $(Y-\\hat f(X))^2$ (squared-loss), $|Y-\\hat f(X)|$ (absolute value/$L^1$ loss), $1\\{Y\\ne \\hat f(X)\\}$ （0-1 loss）and $-Y_i\\log(\\hat g(X_i))-(1-Y_i)\\log(1-\\hat g(X_i))$ (cross-entropy). \n",
    "\n",
    "</font>\n",
    "    \n",
    "------------\n",
    "\n",
    "As is clear from the above problem formulation, our goal is not to build a model that minimizes the prediction error on any specific data set (even not the validation or testing set). Instead, supervised learning seeks to minimize the prediction error on the entire population (even beyond the current population, please think about this from a probablistic perspective).\n",
    "\n",
    "In the next two sections, we will introduce two systematic approaches to select the \"best\" model and evaluate the generalization error of the selected model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>\n",
    "# 2. Train-Validate-Test Triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised learning, a key problem is to effectively and efficiently select a prediction model with the smallest **generalization error** using a data set at hand $\\mathcal D:=\\{Y_i,X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$. The set of candidate models is denoted as $\\mathcal F:=\\{f_1(\\cdot),f_2(\\cdot),...,f_L(\\cdot)\\}$. The loss function is denoted as $\\mathcal L(\\cdot,\\cdot)$. The core idea of the train-validate-test triplet approach is that using the data following the same distribution as the population but not overlapping with the data used to train the model could unbiasedly estimate the generalization error. We summarize the entire train-validate-test procedure as follows:\n",
    "\n",
    "-------------\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "- **Step 1. Data Split.** Randomly split the data $\\mathcal D$ into 3 nonoverlapping subsets: $\\mathcal D_{tr}$ for training (i.e., to fit a machine learning model), $\\mathcal D_{va}$ for validation (to pick up the best model), and $\\mathcal D_{te}$ for testing (to evaluate the selected model). Usually most of the data should be put to $\\mathcal D_{tr}$ and a smaller portion should be allocated to $\\mathcal D_{va}$ or $\\mathcal D_{te}$.\n",
    "\n",
    "- **Step 2. Training.** Using the training set $\\mathcal D_{tr}$, train a model for each candidate in $\\mathcal F$, which we denote as $\\hat{\\mathcal{F}}=\\{\\hat f_1,\\hat f_2,...,\\hat f_L\\}$.\n",
    "\n",
    "- **Step 3. Validation.** Use the validation set $\\mathcal D_{va}$ to estimate the generalization error of each model $\\hat f_i\\in\\hat{\\mathcal{F}}$:\n",
    "\n",
    "$$\\mathbb E[\\mathcal L(Y,\\hat f_i(X))]\\approx \\hat e_i=\\frac{1}{|\\mathcal D_{va}|}\\sum_{j\\in \\mathcal D_{va}} \\mathcal L(Y_j,\\hat f_i(X_j))$$\n",
    "where $|\\mathcal D_{va}|$ is the sample size of the validation data set $\\mathcal D_{va}$.\n",
    "\n",
    "Select the model with the smallest generalization error, which we denote as $\\hat e_*=\\min\\{\\hat e_1,\\hat e_2,...,\\hat e_L\\}$, and the selected model is denoted as $\\hat f_*(\\cdot)$:\n",
    "\n",
    "$$\\hat f_*(\\cdot)=\\mbox{argmin}_{\\hat f(\\cdot)\\in \\hat{\\mathcal{F}}}\\frac{1}{|\\mathcal D_{va}|}\\sum_{j\\in \\mathcal D_{va}} \\mathcal L(Y_j,\\hat f(X_j))$$\n",
    "\n",
    "- **Step 4. Testing.** Finally, use the testing data set $\\mathcal D_{te}$ to evaluate the generalization error of the selected model $\\hat f_*(\\cdot)$:\n",
    "\n",
    "$$\\hat{err}_*=\\frac{1}{|\\mathcal D_{te}|}\\sum_{j\\in \\mathcal D_{te}} \\mathcal L(Y_j,\\hat f_*(X_j))$$\n",
    "where $|\\mathcal D_{te}|$ is the sample size of the testing set $\\mathcal D_{te}$.\n",
    "\n",
    "Then, $\\hat{err}_*$ is an unbiased estimation of the true generalization error for the \"best\" model in $\\mathcal F$. \n",
    "\n",
    "</font>\n",
    "\n",
    "----------------\n",
    "\n",
    "\n",
    "One should also note that $\\hat e_*$ is an **underestimate** of the generalization error. If one only cares about selecting the optimal model, but not the performance of the optimal model, we only need to split the data into two parts, training and validation so that the validation-error minimization model can be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Train-Validate-Test in Action: the Kwai User Retention Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now revisit the user retention prediction problem of Kwai. Recall that we use the following short-term consumption behaviors of 28 days (from day-$(t-27)$ to day-$t$) to predict whether a user will be active on the platform between day-$(t+28)$ and day-$(t+34)$. :\n",
    "\n",
    "- The user's total video watching time (in minutes) of the 28 days spent on the hot page (发现页);\n",
    "- The user's total video watching time (in minutes) of the 28 days spent on the follow page (关注页);\n",
    "- The user's total live watching time (in minutes) of the 28 days spent on the follow page (关注页);\n",
    "- The user's total video watching time (in minutes) of the 28 days spent on the nearby page (同城页);\n",
    "- The user's total live watching time (in minutes) of the 28 days spent on the nearby page (同城页);\n",
    "- The user's total time (in minutes) of the 28 days spent on the comment area (评论区);\n",
    "- The user's total number of comments of the 28 days posted on the comment area.\n",
    "\n",
    "As a demonstration of the train-validate-test triplet, we examine two candidate models: \n",
    "\n",
    "- **Model1:** logistic regression model with all consumption variables as features;\n",
    "- **Model2:** logistic regression model with only video consumptions as features. \n",
    "\n",
    "The performance metrics we will use in this demonstration is **AUC**.\n",
    "\n",
    "To begin with, We first read the data set ``Kwai_Retention.csv`` and take a look at the first few rows of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import sklearn\n",
    "import scipy as sp\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Set the random seed such that the results are replicable.\n",
    "\n",
    "random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>retention</th>\n",
       "      <th>h_video</th>\n",
       "      <th>f_video</th>\n",
       "      <th>f_live</th>\n",
       "      <th>n_video</th>\n",
       "      <th>n_live</th>\n",
       "      <th>comment_duration</th>\n",
       "      <th>comment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.333127</td>\n",
       "      <td>82.440787</td>\n",
       "      <td>50.715540</td>\n",
       "      <td>25.448967</td>\n",
       "      <td>31.928108</td>\n",
       "      <td>24.547305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>169.315973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.053897</td>\n",
       "      <td>0.873836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.886263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.932622</td>\n",
       "      <td>55.413817</td>\n",
       "      <td>136.752137</td>\n",
       "      <td>9.372263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>180.547294</td>\n",
       "      <td>67.597604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.487704</td>\n",
       "      <td>13.855340</td>\n",
       "      <td>23.045255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>124.664241</td>\n",
       "      <td>81.037966</td>\n",
       "      <td>156.721750</td>\n",
       "      <td>37.109027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.401544</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  retention     h_video    f_video      f_live    n_video  \\\n",
       "0        1          1   14.333127  82.440787   50.715540  25.448967   \n",
       "1        2          0    0.000000   0.000000  169.315973   0.000000   \n",
       "2        3          1   24.886263   0.000000    8.932622  55.413817   \n",
       "3        4          0  180.547294  67.597604    0.000000   9.487704   \n",
       "4        5          1  124.664241  81.037966  156.721750  37.109027   \n",
       "\n",
       "       n_live  comment_duration  comment_num  \n",
       "0   31.928108         24.547305            2  \n",
       "1  100.053897          0.873836            0  \n",
       "2  136.752137          9.372263            1  \n",
       "3   13.855340         23.045255            2  \n",
       "4    0.000000         26.401544            3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwai_retention = pd.read_csv(\"Kwai_Retention.csv\")\n",
    "kwai_retention.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we randomly split the data set into 3 parts, 60% into the training set, 20% into the validation set, 20% into the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = kwai_retention.drop(columns=['user_id','retention'])\n",
    "y = kwai_retention['retention'].ravel()\n",
    "\n",
    "# First randomly select 60% of the data into the training set.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "# Then randomly select 50% of the rest of the data into testing set.\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 7)\n",
      "(20000, 7)\n",
      "(20000, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train both models on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogitReg\n",
    "\n",
    "LR_1 = LogitReg().fit(X_train,y_train)\n",
    "LR_2 = LogitReg().fit(X_train[['h_video','f_video','n_video']],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the out-of-sample AUC of each model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  roc_curve, auc\n",
    "\n",
    "# Compute the AUC for model 1.\n",
    "fpr_1,tpr_1,thresholds_1 = roc_curve(y_validate, LR_1.predict_proba(X_validate)[:,1])\n",
    "roc_auc_1 = auc(fpr_1,tpr_1)\n",
    "\n",
    "# Compute the AUC for model 2.\n",
    "fpr_2,tpr_2,thresholds_2 = roc_curve(y_validate, LR_2.predict_proba(X_validate[['h_video','f_video','n_video']])[:,1])\n",
    "roc_auc_2 = auc(fpr_2,tpr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation AUC of Model 1 is 0.7272.\n",
      "The validation AUC of Model 2 is 0.6695.\n"
     ]
    }
   ],
   "source": [
    "print('The validation AUC of Model 1 is %0.4f.'% roc_auc_1)\n",
    "print('The validation AUC of Model 2 is %0.4f.'% roc_auc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the validation AUC of Model 1 is slightly better than that of Model 2. Therefore, we select Model 1 and test its generalization AUC on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing AUC of Model 1 is 0.7323.\n"
     ]
    }
   ],
   "source": [
    "fpr_te,tpr_te,thresholds_te = roc_curve(y_test, LR_1.predict_proba(X_test)[:,1])\n",
    "roc_auc_te = auc(fpr_te,tpr_te)\n",
    "\n",
    "print('The testing AUC of Model 1 is %0.4f.' % roc_auc_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the testing AUC of Model 1 is 0.733, which is a unbiased estimate of the \"true\" generalization AUC of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>\n",
    "# 3. $K-$Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to systematically select a supervised learning model and evaluate its generalization error is $k-$fold cross validation ([Wiki Page](https://en.wikipedia.org/wiki/Cross-validation_(statistics))). One key drawback of the training-validation-testing triplet is that it requires a lot of data. Cross-validation, however, helps reduce the amount of data needed to select the optimal model and estimate the generalization error. \n",
    "\n",
    "The key idea of cross-validation is that we split the data into different parts, and use some parts to fit the model and some parts to validate the model. Furthermore, we repeat the above process the other way arround by switching the training and validationing sets. \n",
    "\n",
    "As with the training-validation-testing triplet, the data set at hand is denoted as $\\mathcal D:=\\{Y_i,X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$, the set of candidate models is denoted as $\\mathcal F:=\\{f_1(\\cdot),f_2(\\cdot),...,f_L(\\cdot)\\}$, and the loss function is denoted as $\\mathcal L(\\cdot,\\cdot)$. The $k-$fold cross validation procedure is performed as follows:\n",
    "\n",
    "\n",
    "-----\n",
    "<font color=red>\n",
    "\n",
    "- **Step 1. Data Split.** Randomly split the data $\\mathcal D$ into 2 nonoverlapping subsets: $\\mathcal D_{tr}$ for training (i.e., to fit and cross-validate a machine learning model), and $\\mathcal D_{te}$ for testing (to evaluate the selected model). Usually most of the data should be put to $\\mathcal D_{tr}$ and a smaller portion should be allocated to $\\mathcal D_{te}$.\n",
    "\n",
    "- **Step 2. $k-$Fold Training Data.** Randomly split the training data $\\mathcal D_{tr}$ into $k$ parts of equal size, which we denote as $\\mathcal D^1,\\mathcal D^2,...,\\mathcal D^k$.\n",
    "\n",
    "- **Step 3. Cross-Validation.** For each model in $l\\in\\mathcal F$, train this model on $k-1$ parts of the training data $\\{\\mathcal D^1,\\mathcal D^2,...,\\mathcal D^{i-1},\\mathcal D^{i+1},...,\\mathcal D^k\\}$, and estimate the generalization error on the remaining part $\\mathcal D^i$, denoted as $\\hat e_l^i$. The average generalization error of model $l$ is therefore\n",
    "\n",
    "$$\\hat e_l=\\frac{1}{k}\\sum_{i=1}^k\\hat e_l^i$$\n",
    "\n",
    "- **Step 4. Model Selection.** Select the model with the smallest average generalization error, which we denote as $\\hat e_{i^*}=\\min\\{\\hat e_1,\\hat e_2,...,\\hat e_L\\}$. Retrain model $f_{i^*}(\\cdot)$ on the entire training set $\\mathcal D_{tr}$, which we obtain $\\hat f^{cv}_*(\\cdot)$.\n",
    "\n",
    "- **Step 5. Testing.** Finally, use the testing data set $\\mathcal D_{te}$ to evaluate the generalization error of the selected model $\\hat f^{cv}_*(\\cdot)$, which we denote as $\\hat{err}^{cv}_*$.\n",
    "\n",
    "Then, $\\hat{err}^{cv}_*$ is an unbiased estimation of the true generalization error for the \"best\" model in $\\mathcal F$. In theory, if the sample size of the training set $|\\mathcal D_{tr}|$ is sufficiently large, the smallest average generalization error of cross validation, $\\hat e_{i^*}$ will also converge to the true generalization error. \n",
    "\n",
    "</font>\n",
    "\n",
    "------\n",
    "\n",
    "An advantage of the cross-validation approach over the train-validate-test approach is that it has a smaller variances since the performance evaluation produced by cross-validation is averaged accross errors of different rounds. The number of iterations/folds for cross-validation, $k$, is usually set between 5 and 10. \n",
    "\n",
    "We illustrate the $k-$fold cross validation procedure as the following figure:\n",
    "\n",
    "<img src=\"kfolds.png\" width=800>\n",
    "\n",
    "Next, we introduce a demostration to show how to implement cross validation in Python by fine-tuning the number-of-neighbor parameter $k$ in the $k-$NN algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.  Case Study: $k-$Fold Cross Validation for $k-$NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the $k-$Fold Cross Validation framework to select the best number of neighbors for $k-$NN. Specifically, we want to select the best $k-$NN model to predict the long-term user retention for Kwai.\n",
    "\n",
    "To begin with, we read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>retention</th>\n",
       "      <th>h_video</th>\n",
       "      <th>f_video</th>\n",
       "      <th>f_live</th>\n",
       "      <th>n_video</th>\n",
       "      <th>n_live</th>\n",
       "      <th>comment_duration</th>\n",
       "      <th>comment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.333127</td>\n",
       "      <td>82.440787</td>\n",
       "      <td>50.715540</td>\n",
       "      <td>25.448967</td>\n",
       "      <td>31.928108</td>\n",
       "      <td>24.547305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>169.315973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.053897</td>\n",
       "      <td>0.873836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.886263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.932622</td>\n",
       "      <td>55.413817</td>\n",
       "      <td>136.752137</td>\n",
       "      <td>9.372263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>180.547294</td>\n",
       "      <td>67.597604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.487704</td>\n",
       "      <td>13.855340</td>\n",
       "      <td>23.045255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>124.664241</td>\n",
       "      <td>81.037966</td>\n",
       "      <td>156.721750</td>\n",
       "      <td>37.109027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.401544</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  retention     h_video    f_video      f_live    n_video  \\\n",
       "0        1          1   14.333127  82.440787   50.715540  25.448967   \n",
       "1        2          0    0.000000   0.000000  169.315973   0.000000   \n",
       "2        3          1   24.886263   0.000000    8.932622  55.413817   \n",
       "3        4          0  180.547294  67.597604    0.000000   9.487704   \n",
       "4        5          1  124.664241  81.037966  156.721750  37.109027   \n",
       "\n",
       "       n_live  comment_duration  comment_num  \n",
       "0   31.928108         24.547305            2  \n",
       "1  100.053897          0.873836            0  \n",
       "2  136.752137          9.372263            1  \n",
       "3   13.855340         23.045255            2  \n",
       "4    0.000000         26.401544            3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwai_retention = pd.read_csv(\"Kwai_Retention.csv\")\n",
    "kwai_retention.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we randomly split the data into training and validation sets by randomly sample 70% of the data into the training set and the rest into the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kwai_retention.drop(columns=['retention','user_id'])\n",
    "y = kwai_retention['retention'].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, for $k-$NN, we need to standardize the features by substracting their mean (of the training set) and devide by their standard deviation (of the training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test),columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load necessary packages for cross-validation and $k-$NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use 5-fold cross-validation to fine-tune the number-of-neighbor $k$ in the $k$NN model. The [documentation for GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k is  {'n_neighbors': 10}\n",
      "\n",
      "\n",
      "The AUC associated with the best k is 0.6764.\n"
     ]
    }
   ],
   "source": [
    "# The candidate models/hypter-parameters: $k-$NN (k=1,2,...,10)\n",
    "\n",
    "# The possible values of the hyper-parameter n_neighbors (k)\n",
    "param_grid = [{'n_neighbors':range(1,11)}]\n",
    "\n",
    "# The model is the kNN classifier\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# The evaluation method is AUC.\n",
    "grid_1 = GridSearchCV(clf, param_grid, scoring = 'roc_auc',cv=5)\n",
    "\n",
    "# Fit the model and perform k-fold cross-validation.\n",
    "grid_1.fit(X_train,y_train)\n",
    "\n",
    "print(\"The best k is \",grid_1.best_params_) \n",
    "print(\"\\n\") \n",
    "print(\"The AUC associated with the best k is %0.4f.\" % grid_1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cross-validation results, we know that the best $k$NN model is obtained when $k=10$. So we fit a 10-NN model on the entire training set. First, we make predictions on the testing set based on the $10-$NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing AUC for the 10-NN model is 0.6765.\n"
     ]
    }
   ],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors = 10).fit(X_train,y_train)\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_test, kNN.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "print('The testing AUC for the 10-NN model is %0.4f.' % roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also print the confusion matrix and calculate the accuracy of the predicted outcomes and evaluate the model accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, kNN.predict(X_test)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    predicted\n",
      "         --------------------\n",
      "Acutal   |0        |1        \n",
      "-----------------------------\n",
      "0        |3757     |5361     \n",
      "-----------------------------\n",
      "1        |4024     |16858    \n"
     ]
    }
   ],
   "source": [
    "def printCM(tn, fp, fn, tp):\n",
    "    print('{: <9} {: <9} {: <9}'.format(' ',' ','predicted'))\n",
    "    print('         --------------------')\n",
    "    print('{: <9}|{: <9d}|{: <9d}'.format('Acutal',0,1))\n",
    "    print('-----------------------------')\n",
    "    print('{: <9d}|{: <9d}|{: <9d}'.format(0,tn,fp))\n",
    "    print('-----------------------------')\n",
    "    print('{: <9d}|{: <9d}|{: <9d}'.format(1,fn,tp))\n",
    "printCM(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy of 10-NN model is 0.6872\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "print('The testing accuracy of 10-NN model is %0.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_4'></a>\n",
    "# 4. Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to characterize a fundamentally (and notorious) issue in supervised learning: the Bias-Variance trade-off ([Wiki Page](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)). This trade-off is so fundamental and prevalent that it offers some actionable insights on how we could reduce the total geeneralization error of a supervised model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first present the decomposition of error into bias, variance, and noise terms, which highlights the intrinsic trade-off between bias and variance. We consider a data sample $\\mathcal D=\\{Y_i,X_{ij}:1\\le i\\le n,1\\le j \\le p\\}\\}$. For notational simplicity, we make a functional assumption that, for each $i$, $Y_i=f(X_i)+\\epsilon_i$, where $f(\\cdot)$ is a real-valued function and $\\epsilon_i$ has mean zero ($\\mathbb E[\\epsilon_i]=0$). For a new data in the general population $(X,Y)$ also satisfies this functional form: $Y=f(X)+\\epsilon$, where $X$ follows the same distribution as $X_i$ and $\\epsilon$ follows from the same distribution as $\\epsilon_i$ for each $i$. Based on the sample data $\\mathcal D$, we train a model $\\hat f(\\cdot,\\mathcal D)$, where we explicitly specify the dependence of the model on the training set $\\mathcal D$. Our goal is to find $\\hat f(X,\\mathcal D)$ that approximates the true data generating function $f(X)$ as close as possible for all $X$ in the population, measured by a certain loss function $\\mathcal L(\\cdot,\\cdot)$. In this section, we focus on the squared loss: $(Y-\\hat f(X,\\mathcal D))^2$ \n",
    "\n",
    "In fact, regardless of how we train the model $\\hat f(\\cdot,\\mathcal D)$, we have the following decomposition of the squared loss for an unseen data $(X,Y)\\notin \\mathcal D$:\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\underbrace{\\mathbb E_{\\mathcal D}[(Y-\\hat f(X,\\mathcal D))^2]}_{\\mbox{Squared Error}}=\\underbrace{(\\mathbb E_{\\mathcal D}[\\hat f(X,\\mathcal D)]-f(X))^2}_{\\mbox{Bias}} + \\underbrace{\\mathbb E_{\\mathcal D}[(\\mathbb E_{\\mathcal D}[\\hat f(X,\\mathcal D)]-\\hat f(X,\\mathcal D))^2]}_{\\mbox{Variance}}+\\underbrace{Var (\\epsilon)}_{\\mbox{Noise}}$$\n",
    "\n",
    "</font>\n",
    "\n",
    "where $Var(\\cdot)$ refers to taking variance, and the expectation $\\mathbb E_{\\mathcal D}(\\cdot)$ is taken with respect to the training set $\\mathcal D$ sampled from underlying \"true\" data generating process of $(X,Y)$. The above three terms have the following interpretations:\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "- **Bias** is the inherent error with your model caused by, e.g., simplifying assumptions, even with infinitely many training data. As is clear from its definition, the bias term measures how far away is the fitted model $\\hat f(\\cdot,\\mathcal D)$ from the \"true model\" $f(\\cdot)$ under the underlying data generating process. It essentially captures the degree of underfitting for the model trained on $\\mathcal D$.\n",
    "\n",
    "- **Variance** is the amount of the change the model will have if trained on a different data set. As is clear from its definition, the variance term measures how far away is the fitted outcome $\\hat f(X,\\mathcal D)$ from its mean under the true data generating process. It essentially captures the degree of overfitting for the model.\n",
    "\n",
    "- **Noise** is the variance of the intrinsic error $\\epsilon$, which is independent of the choice of model.\n",
    "</font>\n",
    "\n",
    "-----------------\n",
    "\n",
    "A pictorial illustration of the bias and variance can be found in the following picture:\n",
    "\n",
    "<img src=\"target.png\" width=500>\n",
    "\n",
    "From the bias-variance decomposition formula, we know that both bias and variance are sensitive to the model $\\hat f(\\cdot,\\mathcal D)$. We have the following figure to demonstrate the trade-off between bias and variance under different model complexities.\n",
    "\n",
    "<img src=\"Overfitting.png\" width=750>\n",
    "\n",
    "\n",
    "\n",
    "As shown by the figure above, a more complex model could have more flexibilities to fit the \"true\" model (also called the ground truth in the machine learning community) so that the bias will decrease in this case. Meanwhile, it may overfit the training data so that the variance of the model may be too high. On the other hand, a less complex model would not be that sensitive to changes in the training set (low variance), but may be too simple to capture the true model (high bias). In the following figure, we demonstrate this bias-variance tradeoff and show how total generalization error changes with model complexity. As we can see, the total generalization error is minimized when the model complexity is at a moderate sweet spot.\n",
    "\n",
    "<img src=\"biasvariance.png\" width=500>\n",
    "\n",
    "Next subsection is devoted to a systematic way of addressing over-fitting: Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization ([Wiki Page](https://en.wikipedia.org/wiki/Regularization_(mathematics) )) refers to a systematic approach to address the overfitting problem of overly complex models by introducing a penalty term in the objective function that penalizes an overly complex model. Specifically, given a training data set $\\mathcal D=\\{Y_i,X_{ij}:1\\le i\\le n,1\\le j \\le p\\}\\}$, a family of models $\\mathcal F$, and the loss function $\\mathcal L(\\cdot,\\cdot)$, the unregularized training is to find a model $\\hat f(\\cdot)$ that minimizes the in-sample error.\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\hat f(\\cdot)=\\mbox{argmin}_{f(\\cdot)\\in\\mathcal F}\\frac{1}{n}\\sum_{i=1}^n\\mathcal L(Y_i,f(X_i))$$\n",
    "\n",
    "</font>\n",
    "    \n",
    "Under regularization, we introduce a regularizer, or a penality function associated with the model $R(f)\\ge0$. In particular, if $f$ is more complex, $R(f)$ will become larger. The model complexity is represented differently for different models. For a linear regression or logistic regression, a more complex model means the number of features $p$ is larger. For $k$-NN, a more complex model means $k$ is small. We will discuss what it means by mode complexity for other machine learning models as we discuss them.  \n",
    "\n",
    "The regularized model fitting is performed as follows:\n",
    "\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "\n",
    "$$\\hat f(\\cdot,\\lambda)=\\mbox{argmin}_{f(\\cdot)\\in\\mathcal F}[\\underbrace{\\frac{1}{n}\\sum_{i=1}^n\\mathcal L(Y_i,f(X_i))}_{\\mbox{Loss}}+\\underbrace{\\lambda R(f)}_{\\mbox{Penalty}}]$$\n",
    "    \n",
    "</font>\n",
    "\n",
    "where the hyper parameter $\\lambda\\ge0$. The regularization term $\\lambda R(f)$ penalizes overly complex models. In particular, the parameter $\\lambda$ trades off bias (under-fitting) and variance (over-fitting). Let us now introduce some commonly used regularized regressions:\n",
    "\n",
    "- **Lasso linear regression**: \n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\hat\\beta=\\mbox{argmin}_{\\beta}\\underbrace{\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\beta_0-\\sum_{j=1}^p\\beta_jX_{ij})^2}_{\\mbox{Loss}}+\\underbrace{\\lambda\\sum_{j=1}^p|\\beta_j|}_{\\mbox{Penalty}}$$\n",
    "\n",
    "</font>\n",
    "\n",
    "In lasso regression, the loss is usually referred to as the mean square error and the penalty is called $L^1$ penalty.\n",
    "\n",
    "- **Ridge linear regression**:\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\hat\\beta=\\mbox{argmin}_{\\beta}\\underbrace{\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\beta_0-\\sum_{j=1}^p\\beta_jX_{ij})^2}_{\\mbox{Loss}}+\\underbrace{\\frac{\\lambda}{2}\\sum_{j=1}^p|\\beta_j|^2}_{\\mbox{Penalty}}$$\n",
    "\n",
    "</font>\n",
    "\n",
    "In ridge regression, the loss is also the mean square error and the penalty is called $L^2$ penalty.\n",
    "\n",
    "- **Elastic net linear regression**: \n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\hat\\beta=\\mbox{argmin}_{\\beta}\\underbrace{\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\beta_0-\\sum_{j=1}^p\\beta_jX_{ij})^2}_{\\mbox{Loss}}+\\underbrace{\\lambda\\sum_{j=1}^p[\\frac{1}{2}(1-\\alpha)|\\beta_j|^2+\\alpha|\\beta_j|]}_{\\mbox{Penalty}}$$\n",
    "\n",
    "</font>\n",
    "Clearly, the elastic net linear regression is a combination of lasso ($\\alpha=1$) and ridge ($\\alpha=0$) regressions ([Wiki Page](https://en.wikipedia.org/wiki/Elastic_net_regularization)).\n",
    "\n",
    "- **Lasso logistic regression**: We can also regularize logistic regression by substracting $L^1$ and $L^2$ penalties to the maximum likelihood estimation:\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\hat\\beta=\\mbox{argmax}_{\\beta}\\underbrace{\\sum_{i=1}^n\\left(Y_i\\log\\left(\\frac{\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}{1+\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}\\right)+(1-Y_i)\\log\\left(\\frac{1}{1+\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}\\right)\\right)}_{\\mbox{Log-Likelihood}}-\\underbrace{\\lambda\\sum_{j=1}^p|\\beta_j|}_{\\mbox{Penalty}}$$\n",
    "\n",
    "</font>\n",
    "    \n",
    "- **Ridge logistic regression**: \n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\hat\\beta=\\mbox{argmax}_{\\beta}\\underbrace{\\sum_{i=1}^n\\left(Y_i\\log\\left(\\frac{\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}{1+\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}\\right)+(1-Y_i)\\log\\left(\\frac{1}{1+\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}\\right)\\right)}_{\\mbox{Log-Likelihood}}-\\underbrace{\\frac{\\lambda}{2}\\sum_{j=1}^p|\\beta_j|^2}_{\\mbox{Penalty}}$$\n",
    "\n",
    "</font>    \n",
    "Finally, we briefly discuss the properties of lasso ($L^1$) and ridge ($L^2$) regularizations. From their formmulation, we know that lasso and ridge will shrink the estimated coefficients $\\hat \\beta$ to 0. Only the most explanatory features will be retained with regularized regressions. In particular, lasso typitcally yields much fewer non-zero entries of $\\hat\\beta$ than ridge or OLS. Thus, lasso shrinks $\\hat\\beta$ to 0 more sharply. For ridge regression, it shrinks $\\hat\\beta$'s to zero more softly. As is shown in the following figure (where $L1$ refers lasso regression and $L2$ refers to ridge regression), with $L2$ regularizer, the variable that minimizes the function $f(x)+\\alpha|x|^2$ is closer to 0 than the minimizer of $f(x)=(2x-1)^2$. With $L1$ regularizer, the minimizer of $f(x)+\\alpha |x|$ is directly shrinked to 0.  \n",
    "\n",
    "<img src=\"L1L2.png\" width=750>\n",
    "\n",
    "We usually use the train-validate-test triplet or cross validation to fine tune the parameter $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Regularization Case Study: Boston Housing Price "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston housing data set is a commonly used one in machine learning. This data set contains the following variables:\n",
    "\n",
    "- **CRIM**: Per capita crime rate\n",
    "- **ZN**: How much of the land is zoned for large residential properties\n",
    "- **INDUS**: Proportion of the area used for industry\n",
    "- **CHAS**: Binary variable, 1 if a census tract is next to the Charles River\n",
    "- **NOX**: Concentration of nitrous oxides in the air, a measure of air pollution\n",
    "- **RM**: Average number of rooms per dwelling\n",
    "- **AGE**: Proportion of owner-occupied units built before 1940\n",
    "- **DIS**: Measure of how far the tract is from centers of employment in Boston\n",
    "- **RAD**: Measure of closeness to important highways\n",
    "- **TAX**: Property tax per 10,000 dollars of value\n",
    "- **PTRATIO**: Pupil to teacher ratio by town\n",
    "- **TRACT**: Index of the tract\n",
    "- **lstat**: Percentage values of lower status population. \n",
    "- **MEDV (outcome variable)**: Median value of owner-occupied homes, measured in thousands of dollars\n",
    "\n",
    "Our job is to use cross-validation to fine tune the regularization parameter $\\lambda$ in lasso regression. To begin with, we load the data into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  b        506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_BH = pd.read_csv(\"BostonHousing.csv\")\n",
    "df_BH.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the ```ElasticNet``` package. See [this documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ElasticNet model\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly split the data into training and testing sets, the former with 70% of the data and the latter with 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  df_BH.drop(columns=['medv'])\n",
    "y = df_BH['medv'].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use cross-validation to fine tune the regularization parameter $\\lambda$. We set the number of folds to be 5. In ```sklearn.linear_model.ElasticNet```, the parameter $\\lambda$ is named as ```alpha```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha parameter is {'alpha': 0.01}\n",
      "\n",
      "\n",
      "The corresponding R-squared is 0.7480.\n"
     ]
    }
   ],
   "source": [
    "# Grid: 0.01, 0.02, ..., 0.5\n",
    "param_grid = [{'alpha':np.arange(0.01,0.51,0.01)}]\n",
    "\n",
    "# l1_ratio means Lasso\n",
    "Lasso_LinReg = ElasticNet(l1_ratio = 1)\n",
    "grid_1 = GridSearchCV(Lasso_LinReg, param_grid,cv=5)\n",
    "grid_1.fit(X_train,y_train.ravel())\n",
    "print(\"The best alpha parameter is\",grid_1.best_params_) \n",
    "print('\\n') \n",
    "print(\"The corresponding R-squared is %0.4f.\" % grid_1.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00174074, 0.00136299, 0.00132036, 0.00131645, 0.00131469,\n",
       "        0.00131383, 0.00131521, 0.00131445, 0.00141616, 0.00134068,\n",
       "        0.00132661, 0.00134397, 0.00130486, 0.00133963, 0.00145025,\n",
       "        0.00132976, 0.00137353, 0.00133643, 0.00136294, 0.00135689,\n",
       "        0.00135622, 0.00135598, 0.00136456, 0.00139623, 0.00138893,\n",
       "        0.00135255, 0.00134411, 0.0013545 , 0.00135632, 0.0013526 ,\n",
       "        0.00135303, 0.00135455, 0.00137258, 0.0013483 , 0.00134773,\n",
       "        0.00137119, 0.00134234, 0.00135484, 0.00129952, 0.00133762,\n",
       "        0.00136533, 0.00134764, 0.00134349, 0.0013526 , 0.00134273,\n",
       "        0.00133948, 0.00134654, 0.00135527, 0.00132327, 0.00129304]),\n",
       " 'std_fit_time': array([4.04272948e-04, 4.37505304e-05, 1.07611065e-05, 5.27244778e-06,\n",
       "        7.54307554e-06, 7.42642301e-06, 7.84480459e-06, 6.06427393e-06,\n",
       "        1.76910082e-04, 5.68325884e-05, 3.52789898e-05, 3.56730288e-05,\n",
       "        4.57614636e-06, 4.87975681e-05, 1.52082007e-04, 1.94632522e-05,\n",
       "        1.11036219e-04, 3.60148133e-05, 7.52224786e-06, 4.51965165e-06,\n",
       "        1.02376838e-05, 5.52925532e-06, 1.50959445e-05, 4.60651350e-05,\n",
       "        4.76373447e-05, 7.24415932e-06, 3.90191508e-06, 1.35487218e-05,\n",
       "        2.21030354e-05, 9.44739449e-06, 9.85911995e-06, 1.22154103e-05,\n",
       "        8.06903721e-05, 6.23253710e-06, 8.86891477e-06, 3.96438984e-05,\n",
       "        5.23305699e-06, 7.45204492e-05, 5.92622459e-06, 5.48795032e-05,\n",
       "        4.13983089e-05, 4.23177867e-06, 8.13003859e-06, 1.75281603e-05,\n",
       "        6.32308367e-06, 6.49164363e-06, 1.00231125e-05, 3.93575856e-05,\n",
       "        6.25613986e-05, 2.86930000e-05]),\n",
       " 'mean_score_time': array([0.00102859, 0.00097742, 0.00092406, 0.00089936, 0.00089936,\n",
       "        0.00089412, 0.00089521, 0.00089779, 0.00089855, 0.00089793,\n",
       "        0.00092239, 0.00091043, 0.00089145, 0.00095758, 0.00091219,\n",
       "        0.00089841, 0.00090194, 0.0009779 , 0.00092683, 0.0009306 ,\n",
       "        0.00095282, 0.00094023, 0.00093465, 0.00094023, 0.00097361,\n",
       "        0.00093994, 0.00093522, 0.00093241, 0.00093493, 0.00093699,\n",
       "        0.00094299, 0.00093489, 0.00093794, 0.00094533, 0.00103674,\n",
       "        0.00095501, 0.00093317, 0.00090852, 0.00090446, 0.00091701,\n",
       "        0.00094347, 0.0009397 , 0.00093327, 0.00092788, 0.00093236,\n",
       "        0.00094204, 0.00096798, 0.00091681, 0.00093069, 0.00091872]),\n",
       " 'std_score_time': array([5.45909619e-05, 1.51397457e-04, 3.10974609e-05, 4.00202470e-06,\n",
       "        3.71627193e-06, 4.19616699e-06, 1.56994606e-06, 3.65208705e-06,\n",
       "        5.38931473e-06, 3.34942042e-06, 2.40168823e-05, 1.75580999e-05,\n",
       "        1.95445075e-06, 8.21469614e-05, 1.20301016e-05, 2.76154179e-06,\n",
       "        1.63909955e-05, 1.27862228e-04, 4.24251107e-06, 3.02105600e-06,\n",
       "        2.61368535e-05, 7.68669782e-06, 6.40525612e-06, 2.10806251e-05,\n",
       "        4.21629219e-05, 1.44989864e-05, 6.22560172e-06, 2.41921442e-06,\n",
       "        2.94174134e-06, 8.13003859e-06, 4.39466950e-06, 1.99703136e-06,\n",
       "        3.19402600e-05, 8.58704157e-06, 1.48970491e-04, 2.79495732e-05,\n",
       "        5.43887076e-06, 8.80355559e-06, 9.72560790e-07, 2.07264609e-05,\n",
       "        1.15315749e-05, 6.07401454e-06, 6.07775677e-06, 4.38171578e-06,\n",
       "        7.23410846e-06, 1.20200802e-05, 2.48655834e-05, 4.96597914e-06,\n",
       "        1.95099250e-05, 3.38881965e-05]),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.02, 0.03, 0.04, 0.05, 0.060000000000000005,\n",
       "                    0.06999999999999999, 0.08, 0.09, 0.09999999999999999,\n",
       "                    0.11, 0.12, 0.13, 0.14, 0.15000000000000002, 0.16,\n",
       "                    0.17, 0.18000000000000002, 0.19, 0.2,\n",
       "                    0.21000000000000002, 0.22, 0.23, 0.24000000000000002,\n",
       "                    0.25, 0.26, 0.27, 0.28, 0.29000000000000004, 0.3, 0.31,\n",
       "                    0.32, 0.33, 0.34, 0.35000000000000003,\n",
       "                    0.36000000000000004, 0.37, 0.38, 0.39, 0.4,\n",
       "                    0.41000000000000003, 0.42000000000000004, 0.43, 0.44,\n",
       "                    0.45, 0.46, 0.47000000000000003, 0.48000000000000004,\n",
       "                    0.49, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.01},\n",
       "  {'alpha': 0.02},\n",
       "  {'alpha': 0.03},\n",
       "  {'alpha': 0.04},\n",
       "  {'alpha': 0.05},\n",
       "  {'alpha': 0.060000000000000005},\n",
       "  {'alpha': 0.06999999999999999},\n",
       "  {'alpha': 0.08},\n",
       "  {'alpha': 0.09},\n",
       "  {'alpha': 0.09999999999999999},\n",
       "  {'alpha': 0.11},\n",
       "  {'alpha': 0.12},\n",
       "  {'alpha': 0.13},\n",
       "  {'alpha': 0.14},\n",
       "  {'alpha': 0.15000000000000002},\n",
       "  {'alpha': 0.16},\n",
       "  {'alpha': 0.17},\n",
       "  {'alpha': 0.18000000000000002},\n",
       "  {'alpha': 0.19},\n",
       "  {'alpha': 0.2},\n",
       "  {'alpha': 0.21000000000000002},\n",
       "  {'alpha': 0.22},\n",
       "  {'alpha': 0.23},\n",
       "  {'alpha': 0.24000000000000002},\n",
       "  {'alpha': 0.25},\n",
       "  {'alpha': 0.26},\n",
       "  {'alpha': 0.27},\n",
       "  {'alpha': 0.28},\n",
       "  {'alpha': 0.29000000000000004},\n",
       "  {'alpha': 0.3},\n",
       "  {'alpha': 0.31},\n",
       "  {'alpha': 0.32},\n",
       "  {'alpha': 0.33},\n",
       "  {'alpha': 0.34},\n",
       "  {'alpha': 0.35000000000000003},\n",
       "  {'alpha': 0.36000000000000004},\n",
       "  {'alpha': 0.37},\n",
       "  {'alpha': 0.38},\n",
       "  {'alpha': 0.39},\n",
       "  {'alpha': 0.4},\n",
       "  {'alpha': 0.41000000000000003},\n",
       "  {'alpha': 0.42000000000000004},\n",
       "  {'alpha': 0.43},\n",
       "  {'alpha': 0.44},\n",
       "  {'alpha': 0.45},\n",
       "  {'alpha': 0.46},\n",
       "  {'alpha': 0.47000000000000003},\n",
       "  {'alpha': 0.48000000000000004},\n",
       "  {'alpha': 0.49},\n",
       "  {'alpha': 0.5}],\n",
       " 'split0_test_score': array([0.82107278, 0.82133455, 0.82064903, 0.81904507, 0.81652282,\n",
       "        0.815019  , 0.8144481 , 0.81385047, 0.81322662, 0.8125755 ,\n",
       "        0.81189763, 0.81119301, 0.81046226, 0.80970415, 0.8089193 ,\n",
       "        0.80810769, 0.80726942, 0.80640443, 0.8055127 , 0.80470778,\n",
       "        0.80394544, 0.80317413, 0.80239385, 0.80160462, 0.80080641,\n",
       "        0.79999756, 0.79918073, 0.79835532, 0.79752032, 0.79667657,\n",
       "        0.79582405, 0.79496359, 0.79409583, 0.79328848, 0.79247184,\n",
       "        0.79164624, 0.79081167, 0.78996812, 0.78911636, 0.78825483,\n",
       "        0.7873459 , 0.78641174, 0.78546877, 0.78451708, 0.78355667,\n",
       "        0.78258753, 0.78160969, 0.78062313, 0.77962786, 0.77862388]),\n",
       " 'split1_test_score': array([0.72565639, 0.72190521, 0.71727381, 0.7130212 , 0.71496661,\n",
       "        0.71679397, 0.71850305, 0.72009426, 0.72156737, 0.7229224 ,\n",
       "        0.72415933, 0.7252781 , 0.72627877, 0.72716135, 0.72792584,\n",
       "        0.72857223, 0.72912001, 0.72955323, 0.72986808, 0.73006437,\n",
       "        0.73024688, 0.73049302, 0.73072573, 0.73094546, 0.73115199,\n",
       "        0.73134532, 0.73152544, 0.73169237, 0.73184609, 0.73198661,\n",
       "        0.73211393, 0.73222806, 0.73232898, 0.7324167 , 0.73249123,\n",
       "        0.73255255, 0.73260067, 0.7326356 , 0.73265732, 0.73266584,\n",
       "        0.73266116, 0.73264329, 0.73261221, 0.7325677 , 0.73251022,\n",
       "        0.73243954, 0.73235567, 0.73225859, 0.73214831, 0.73202484]),\n",
       " 'split2_test_score': array([0.78894978, 0.78849775, 0.78640948, 0.78259207, 0.77752453,\n",
       "        0.77800065, 0.77844292, 0.77885175, 0.77922694, 0.77956823,\n",
       "        0.77987611, 0.78015034, 0.78039092, 0.78059786, 0.78077116,\n",
       "        0.78091104, 0.78101704, 0.78108941, 0.78112814, 0.78115107,\n",
       "        0.78114622, 0.78104471, 0.78092763, 0.78080308, 0.78067106,\n",
       "        0.78053157, 0.78038463, 0.78023022, 0.78006835, 0.77989902,\n",
       "        0.77972223, 0.77953797, 0.77941115, 0.7793407 , 0.77926461,\n",
       "        0.7791829 , 0.77909501, 0.77900207, 0.77886318, 0.77864951,\n",
       "        0.77842886, 0.77820121, 0.77796656, 0.7777244 , 0.77747573,\n",
       "        0.77722007, 0.77695739, 0.7766877 , 0.77641102, 0.77612734]),\n",
       " 'split3_test_score': array([0.82712791, 0.82765103, 0.82719989, 0.82579685, 0.82344192,\n",
       "        0.821404  , 0.82033143, 0.81923449, 0.81811316, 0.81696746,\n",
       "        0.81579739, 0.81460294, 0.81338412, 0.81214091, 0.81100374,\n",
       "        0.81053628, 0.81006012, 0.80957545, 0.80908218, 0.80858032,\n",
       "        0.80806984, 0.80755077, 0.8070231 , 0.80648682, 0.80594195,\n",
       "        0.80538847, 0.80482628, 0.80425559, 0.80367631, 0.80308845,\n",
       "        0.80249206, 0.80189705, 0.80138279, 0.80086114, 0.80033217,\n",
       "        0.79979585, 0.7992522 , 0.79870121, 0.79809402, 0.79744575,\n",
       "        0.7967893 , 0.79612465, 0.79545178, 0.79477071, 0.79408145,\n",
       "        0.79338401, 0.79267837, 0.79196453, 0.79124249, 0.79051224]),\n",
       " 'split4_test_score': array([0.57734763, 0.57169465, 0.56505569, 0.55743071, 0.55359989,\n",
       "        0.55191965, 0.55014869, 0.54828671, 0.54660252, 0.54710161,\n",
       "        0.5475896 , 0.54806663, 0.54853288, 0.548988  , 0.54943217,\n",
       "        0.54986538, 0.55028762, 0.55069912, 0.55109945, 0.55148881,\n",
       "        0.55186722, 0.55223467, 0.55259133, 0.55293694, 0.55327145,\n",
       "        0.55352683, 0.55376349, 0.5539901 , 0.55420667, 0.55441321,\n",
       "        0.55460969, 0.55479614, 0.55497255, 0.55513893, 0.55529526,\n",
       "        0.55544155, 0.5555778 , 0.55570401, 0.55582018, 0.55592632,\n",
       "        0.5560224 , 0.55610845, 0.55618446, 0.55625043, 0.55630635,\n",
       "        0.55635224, 0.55640793, 0.55646182, 0.55650766, 0.55654587]),\n",
       " 'mean_test_score': array([0.7480309 , 0.74621664, 0.74331758, 0.73957718, 0.73721116,\n",
       "        0.73662745, 0.73637484, 0.73606353, 0.73574732, 0.73582704,\n",
       "        0.73586401, 0.7358582 , 0.73580979, 0.73571846, 0.73561044,\n",
       "        0.73559852, 0.73555084, 0.73546433, 0.73533811, 0.73519847,\n",
       "        0.73505512, 0.73489946, 0.73473233, 0.73455538, 0.73436857,\n",
       "        0.73415795, 0.73393611, 0.73370472, 0.73346355, 0.73321277,\n",
       "        0.73295239, 0.73268456, 0.73243826, 0.73220919, 0.73197102,\n",
       "        0.73172382, 0.73146747, 0.7312022 , 0.73091021, 0.73058845,\n",
       "        0.73024953, 0.72989787, 0.72953675, 0.72916606, 0.72878609,\n",
       "        0.72839668, 0.72800181, 0.72759915, 0.72718747, 0.72676683]),\n",
       " 'std_test_score': array([0.09262743, 0.09498518, 0.09729223, 0.09948046, 0.0995582 ,\n",
       "        0.09955338, 0.09991341, 0.10031371, 0.10065235, 0.10017106,\n",
       "        0.0996913 , 0.09921237, 0.09873371, 0.09825469, 0.09779492,\n",
       "        0.09743987, 0.09708365, 0.09672614, 0.09636721, 0.09602466,\n",
       "        0.09568944, 0.0953466 , 0.09500467, 0.09466454, 0.09432621,\n",
       "        0.0940156 , 0.0937099 , 0.09340572, 0.0931029 , 0.09280157,\n",
       "        0.09250173, 0.09220497, 0.09192991, 0.09167232, 0.09141649,\n",
       "        0.09116248, 0.09091023, 0.09065985, 0.09039986, 0.09012919,\n",
       "        0.0898551 , 0.08958048, 0.08930745, 0.08903595, 0.08876611,\n",
       "        0.08849786, 0.0882235 , 0.08794751, 0.08767235, 0.08739784]),\n",
       " 'rank_test_score': array([ 1,  2,  3,  4,  5,  6,  7,  8, 13, 11,  9, 10, 12, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the cross validation results.\n",
    "\n",
    "grid_1.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, for lasso regression, ``l1_ratio`` is set to 1. We also construct a grid search for $\\lambda$ in the set ``np.arange(0.01,0.51,0.01)``, i.e., all $\\lambda$s between 0.01 and 0.5, with step-size 0.01. As reported in the result above, the best $\\lambda=0.01$. Next, we re-train the model on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample R-squared is 0.6448.\n"
     ]
    }
   ],
   "source": [
    "Lasso_Reg = ElasticNet(l1_ratio = 1,alpha = 0.01).fit(X_train,y_train.ravel())\n",
    "\n",
    "# Compute the testing R-squared.\n",
    "\n",
    "print(\"The out-of-sample R-squared is %0.4f.\" % Lasso_Reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Concluding Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generalization** is the central notion in supervised learning, which refers to the procedure of optimizing the model performance on **unseen** data generated by the **true** data-generating process of the entire population. Train-Validate-Test and $k$-fold cross-validation are standard (and scientifically sound) procedures to select the best model that minimizes the generalization error. Cross-validation is more time-consuming, but more widely used especially when the data is scarce.\n",
    "\n",
    "A fundamental trade-off for supervised learning is the one between **bias** and **variance**, which can be nicely quantified by an elegant decomposition of the generalization error. A **simple** model may not be able to capture the ground-truth and, therefore, suffers from a **high bias**. In contrast, a **complex** model may overfit the training data and, thus, suffers from a **high variance**. A good model represents a wise balance between over-fitting and under-fitting. In practice, the bias-variance trade-off is usually paramerized by some model hyper-parameters that guide the training of the model. Therefore, balancing the bias-variance trade-off is often operationalized through fine-tuning hyper-parameters through enumeration, i.e., grid-search.\n",
    "\n",
    "Besides the grid search method introduced in this ``Jupyter Notebook``, another very commonly used approach to finetune hyper-parameters is the **randomized search** [(See this link for more details.)](https://www.kaggle.com/willkoehrsen/intro-to-model-tuning-grid-and-random-search) method. See also [this paper](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf) and the [documentation for randomized search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). The key idea is that, when the number of parameters we need to fine tune is large, grid search may be too efficient. So we impose a distribution such that the hyper-parameters should follow, and each time we sample a hyper-parameter from the distribution to search for the optimal parameter. We will introduce the randomized search approach in more details later in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
