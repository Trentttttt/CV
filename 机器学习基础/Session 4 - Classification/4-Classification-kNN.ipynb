{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Abstract and Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this document is to discuss the classification problem from a little bit abstract and general perspective. Particular emphasis will be given to the idea of generalization, i.e., the performance of the model on the underlying distribution that generates the data. We will also introduce the k-nearest neighbors model, which is an intuitive, powerful (in terms of prediction accuracy), but not so fast/scalable approach to address a generic prediction problem with discrete outcome variables. The kNN model will also be applied to address the long-term user retention prediction problem at Kwai. This document will present modeling details, case study, and Python code. \n",
    "\n",
    "Below is the outline of this document:\n",
    "\n",
    "- In [Section 1](#section_1), we introduce a general framework for classification models evaluated under the \"true\" underlying data generating process. We also discuss the key challenge of predictive modeling that the underlying population distribution is unknown.\n",
    "\n",
    "- In [Section 2](#section_2), we present the $k-$NN and discuss how it can be fitted. Applying $k-$NN to the case of predicting long-term user retention with short-term consumption features is also discussed.\n",
    "\n",
    "- In [Section 3](#section_3), we provide several remarks on the $k-$NN model, including its model complexity, accuracy, speed, and the $k-$NN regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "# 1. A General Framework for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have witnessed an inherent tension when working with models. Any model is a simplified abstraction of reality and is \"always wrong\". The linear and generalized linear models such as linear regression and logistic regression explicitly make very strong assumptions for the probablistic process that actually generates the data (we call this process the data generating process). Both models assume certain functional forms of the relationship between outcome $Y$ and feature $X$, as well as the distributions of the random noises associated with the data. One may wonder, if the strong assumptions are invalidated (which is likely to be the case in practice), how we could make accurate predictions in this case. \n",
    "\n",
    "Therefore, we would like to first develop a general framework for classification problems. Examples include predicting\n",
    "  \n",
    "- Whether a user will watch a movie on Netflix;\n",
    "- Whether a user will click an advertisement on Kwai;\n",
    "- Whether a patient has lung cancer;\n",
    "- Whether an email is spam;\n",
    "- Whether a program should admit a new student;\n",
    "- Many others where the outcome is discrete.\n",
    "\n",
    "\n",
    "For expositional simplicity, we assume $Y\\in\\{0,1\\}$ in this document, i.e., we consider a binary classification. As discussed earlier, the modeling effort should seek to achieve the goal that the prediction error can be controlled as small as possible under the underlying distribution or data generating process of the circumstances where your classifier will be used. For example, if Netflix builds a classification model to predict whether a user will watch a movie, the goal should be that the model can accurately predict whether a randomly sampled user will like a randomly chosen movie on the platform. As a supervised learning paradigm, a classification is trained by examples. Therefore, we assume the training data set $\\mathcal D:=\\{Y_i\\in\\{0,1\\},X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$ is generated from **the same data generating process as the entire population** of interest. We are now ready to formulate the classification problem in the following abstract framework. \n",
    "\n",
    "----\n",
    "\n",
    "<span style=\"font-family:Comic Sans MS\">\n",
    "    <p style=\"color:red\">\n",
    "Given a training data set $\\mathcal D:=\\{Y_i\\in\\{0,1\\},X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$, we seek to find a classifier $\\hat f(\\cdot)$ (also known as a model) which maps from a feature $X$ to the outcomes $\\{0,1\\}$ so that the prediction error under the distribution that generates $\\mathcal D$ (equivalently the entire population) is minimized.\n",
    "        </p>\n",
    "</span>    \n",
    "\n",
    "----\n",
    "\n",
    "For this document, we confine ourselves to the 0-1 loss as the metric to model performance. Specifically, we are interested in minimizing \n",
    "\n",
    "$$\\mbox{0-1 Loss}=\\mathbb P[\\hat f(X)\\ne Y]$$\n",
    "\n",
    "where the probability is calculated under the \"true\" data generating process under which the data $(X,Y)$ is generated. The 0-1 feature simply measures the probability that the classifier will make a wrong prediction, which should be a natural choice of error function under the true distribution that generates the data. One should also note that other commonly used performance measures, such as overall accuracy, false-negative rate, false-positive rate, recall (sensitivity), specificity, precision, receiver operator characteristics (ROC) curve, and area under the curve (AUC) can all be evaluated under the true data generating process. Specifically, we have: \n",
    "\n",
    "- Overall Accuracy = $\\mathbb P[\\hat f(X)= Y]$, i.e., the probability that the model makes a correct prediction;\n",
    "- False-positive rate = $\\mathbb P[\\hat f(X) \\ne Y|Y=0]$, i.e., conditioned on that the actual outcome is negative, the probability that the model makes a wrong prediction;\n",
    "- False-negative rate = $\\mathbb P[\\hat f(X) \\ne Y|Y=1]$, i.e., conditioned on that the actual outcome is positive, the probability that the model makes a wrong prediction;\n",
    "- Recall (sensitivity) = $\\mathbb P[\\hat f(X) = Y|Y=1]$, i.e., conditioned on that the actual outcome is positive, the probability that the model makes a correct prediction;\n",
    "- Specificity = $\\mathbb P[\\hat f(X) = Y|Y=0]$, i.e., conditioned on that the actual outcome is negative, the probability that the model makes a correct prediction;\n",
    "- Precision = $\\mathbb P[\\hat f(X) = Y|\\hat f(X)=1]$, i.e., conditioned on that the predicted outcome is positive, the probability that the model makes a correct prediction;\n",
    "\n",
    "where the above probabilities are all calculated under the \"true\" data generating process. For ROC and AUC, we need a model $\\hat g(X)=\\hat{\\mathbb P}[Y=1|X]$ (such as logistic regression) to predict the conditional probability of a positive outcome given feature $X$. We leave it as an (optional) exercise to plot ROC and compute AUC in this case.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Minimizing the 0-1 Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the general framework, we now discuss how to minimize the 0-1 Loss $\\mathbb P[\\hat f(X)\\ne Y]$. It is clear from our formulation that the classifier $\\hat f(\\cdot)$ that minimizes the 0-1 Loss should satisfy that, for any given $X$, the conditional 0-1 Loss should be minimized, i.e.,:\n",
    "\n",
    "<font color=red>\n",
    "    \n",
    "$$\\hat f(\\cdot)=\\mbox{argmin}_{\\hat F(\\cdot)}\\mathbb P[\\hat F(X)\\ne Y|X]\\mbox{ for any feature vector }X.$$\n",
    "\n",
    "</font>\n",
    "\n",
    "where the probability is taken under the true data generating process. To solve the above minimization problem, we do a simple conditional probability transformation:\n",
    "\n",
    "$$\\mathbb P[\\hat F(X)\\ne Y|X]=\\mathbb P[\\hat F(X)\\ne Y,Y=1|X]+\\mathbb P[\\hat F(X)\\ne Y,Y=0|X]=\\mathbb P[\\hat F(X)=0,Y=1|X]+\\mathbb P[\\hat F(X)=1,Y=0|X]=\\begin{cases}\n",
    "\\mathbb P[Y=1|X],\\mbox{ if }\\hat F(X)=0;\\\\\n",
    "\\mathbb P[Y=0|X],\\mbox{ if }\\hat F(X)=1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Define $P:=\\mathbb P[Y=1|X]$, so $\\mathbb P[Y=0|X]=1-P$. We have the 0-1 Loss associated with the classifier $\\hat F(\\cdot)$ is:\n",
    "\n",
    "$$\\mathbb P[\\hat F(X)\\ne Y|X]=\\begin{cases}\n",
    "P,\\mbox{ if }\\hat F(X)=0;\\\\\n",
    "1-P,\\mbox{ if }\\hat F(X)=1.\n",
    "\\end{cases}$$\n",
    "\n",
    "Furthermore, if $P=\\mathbb P[Y=1|X]\\le 0.5$, $P\\le 1-P$, $\\hat F(X)=0$ yields a lower 0-1 Loss; otherwise, $P>0.5$, $1-P<P$, $\\hat F(X)=1$ yields a lower 0-1 Loss. Therefore, the classifier that minimizes the 0-1 Loss, $\\hat f(\\cdot)$ is given by:\n",
    "\n",
    "<font color=red>\n",
    "$$\\hat f(X)=\n",
    "\\begin{cases}\n",
    "1,\\mbox{ if }\\mathbb P[Y=1|X]>0.5\\\\\n",
    "0,\\mbox{ if }\\mathbb P[Y=1|X]\\le0.5\n",
    "\\end{cases}\n",
    "$$\n",
    "</font>\n",
    "    \n",
    "    \n",
    "This classifier is also very intuitive. To minimize the 0-1 Loss conditioned on feature $X$, it simply predicts the more likely outcome given $X$. The classification problem then boils down to estimate the conditional probability of positive outcome given feature $X$, $\\mathbb P[Y=1|X]$. In practice, we are unable to know the \"true\" underlying population distribution that generates $(X,Y)$, computing $\\mathbb P[Y=1|X]$ is infeasible. Therefore, we need to use some approximation approach to calculate $\\mathbb P[Y=1|X]$ given $X$. Logistic regression is one popular approximation scheme which we assume $\\mathbb P[Y=1|X]=\\frac{\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}{1+\\exp(\\beta_0+\\sum_{j=1}^p\\beta_jX_{ij})}$ and use the fitted logistic regression model \n",
    "$\\hat{\\mathbb P}[Y=1|X]=\\frac{\\exp(\\hat\\beta_0+\\sum_{j=1}^p\\hat\\beta_jX_{ij})}{1+\\exp(\\hat\\beta_0+\\sum_{j=1}^p\\hat\\beta_jX_{ij})}$ to approximate $\\mathbb P[Y=1|X]$. Recall that the logistic regression model is essentially a linear classifier. For some circumstances, the data is generated in a nonlinear fashion, like in the following figure:\n",
    "\n",
    "<img src=\"logistic-not-valid.png\" width=500>\n",
    "\n",
    "Clearly, it does not exist a line that accurately classify the data for this problem. In the next section, we introduce another classification model that works well even if the underlying data generating process is non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>\n",
    "# 2. $k-$Nearest Neighbors ($k-$NN) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another widely used model for classification is the **$k-$Nearest Neighbors ($k-$NN) model** ([Wiki Page](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)). This model estimates $\\mathbb P[Y=1|X]$ and builds a classifier by local averaging. The key assumption of the $k-$NN model is that the distance (in the feature space) reliably reflects similarities in the outcomes.\n",
    "\n",
    "The idea of $k$NN hinges upon the so called law of large numbers ([Wiki Page](https://en.wikipedia.org/wiki/Law_of_large_numbers)). Specifically, to estimate $g(X)=\\mathbb P[Y=1|X]$, it suffices to have an independent sample of labels $\\{y_1,y_2,...,y_k:y_i\\in\\{0,1\\}\\}$ where the feature of all the data points is fixed at $X$. The strong law of large numbers implies that, when $k$ is large,\n",
    "\n",
    "<font color=red>\n",
    "$$g(X)=\\mathbb P[Y=1|X]=\\mathbb E[Y|X]\\approx \\frac{\\sum_{i=1}^ky_i}{k}$$\n",
    "</font>\n",
    "\n",
    "In practice, however, we are unable to construct such an independent sample because there may not be sufficiently many data points in $\\mathcal D$ with feature being $X$. To address this issue, we assume that the distance (in the feature space) reliably reflects similarities in the (distribution of) outcomes. Specifically, we assume the feature space is associated with a distance function (sometimes also called norm, see [Wiki Page](https://en.wikipedia.org/wiki/Norm_(mathematics))), which we denote as $d(X_1,X_2)$, which measures the distance between two feature vectors $X_1$ and $X_2$. In most applications, we use the Euclidean distance (sometimes also called the Euclidean norm or the $L^2-$norm, see [Wiki Page](https://en.wikipedia.org/wiki/Euclidean_distance)) most often. For two feature vectors $X_1=(X_{11},X_{12},...,X_{1p})$ and $X_1=(X_{21},X_{22},...,X_{2p})$, their Euclidean distance is given by\n",
    "\n",
    "$$d(X_1,X_2)=\\sqrt{\\sum_{j=1}^p(X_{1j}-X_{2j})^2}$$\n",
    "\n",
    "\n",
    "Given the training set $\\mathcal D:=\\{Y_i\\in\\{0,1\\},X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$, the $k-$NN model predicts the outcome $Y$ of a new datapoint with feature $X$ by averaging the outcomes of the data points in the training set whose features are closest to $X$. Specifically, we can write out the $k-$NN algorithm as follows:\n",
    "\n",
    "--------\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "1. Compute the distance between $X$ and each data point in $\\mathcal D$, $d_i:=d(X,X_i)$ for all $i=1,2,...,n$.\n",
    "2. Find $k$ data points in $\\mathcal D$ who are closest to $X$, i.e., who have the smallest $d_i$, which we denote as $\\hat{\\mathcal D}_k(X)$.\n",
    "3. Of the $k$ data points in $\\hat{\\mathcal D}_k(X)$, count the number who is with a positive outcome, i.e., $Y_i=1$, which we denote as $\\hat k_1(X)$.\n",
    "4. We estimate that the probability that $Y=1$ is $\\hat g(X)=\\hat P[Y=1|X]=\\frac{\\hat k_1(X)}{k}$. We also take a majority vote to predict the outcome $Y$, i.e., \n",
    "$$\\hat Y=\\hat f(X)=\n",
    "\\begin{cases}\n",
    "1,\\mbox{ if }\\frac{\\hat k_1(X)}{k}>0.5\\\\\n",
    "0,\\mbox{ if }\\frac{\\hat k_1(X)}{k}<0.5\\\\\n",
    "\\mbox{either outcome with equal probability},\\mbox{ if }\\frac{\\hat k_1(X)}{k}=0.5\n",
    "\\end{cases}\n",
    "$$\n",
    "As with the logistic regression model, we can generalize to a classifier with the cutoff threshold $t\\in[0,1]$: $\\hat Y=\\hat f(X)=\\mathbf{1}\\{\\hat g(X)\\ge t\\}$ (for the case of majority vote, $t=0.5$). \n",
    "\n",
    "</font>\n",
    "\n",
    "--------\n",
    "    \n",
    "The above model fitting procedure of the $k-$NN model can be illustrated with the following figure, where we want to predict the outcome of the data with the star feature.\n",
    "\n",
    "<img src=\"knn.png\" width=500>\n",
    "\n",
    "It is clear from the above figure that the prediction outcome depends on the value of $k$. If $k=3$, the model predicts $\\hat{\\mathbb{P}}[Y=A|X]=1/3$ and $\\hat Y=B$. If $k=6$, the model predicts $\\hat{\\mathbb{P}}[Y=A|X]=2/3$ and $\\hat Y=A$. In the special case where $k=n$, the $k-$NN model makes the same prediction that $Y$ is the more frequent outcome of the training set, regardless of the feature $X$. If $k=1$, the $k-$NN model predicts the outcome of a new data point using that of the closest data point in the training set. \n",
    "\n",
    "Before moving on to applying the $k-$NN model to the user retention prediction problem at Kwai, we first discuss an important data preprocessing step: Standardization. More specifically, to use the $k-$NN models for prediction, we should first substract each feature by sample mean and devide by sample standard deviation:\n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\tilde X_{ij}=\\frac{X_{ij}-\\bar{X}_j}{\\hat \\sigma_j}$$\n",
    "\n",
    "</font>\n",
    "    \n",
    "where $\\bar X_j=\\frac{1}{n}(\\sum_{i=1}^nX_{ij})$ is the sample avarage of the training set and $\\hat \\sigma_j=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n(X_{ij}-\\bar X_j)^2}$ is the sample standard deviation of the training set. The rationale for such standardization is that the distances between different features are very sensitive to the scale/unit we use for each feature. Without standardization, $k-$NN may produce some misleading results as illustrated in the following fiture  \n",
    "\n",
    "<img src=\"knn-scale.png\" width=750>\n",
    "\n",
    "It is clear from the above figure that, without scaling/standardization, the first feature will have a much more substantial impact than the second feature on the result of a $k-$NN model, although such imbalance is just a matter of scale but may not reliably reflect the true data generating process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Case: Fitting a $k-$NN Model for Predicting Long-Term User Retention @ Kwai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in class, a central problem for Kwai, a large-scale video-sharing and live-streaming platform, is to user the following short-term consumption behaviors of 28 days (from day-$(t-27)$ to day-$t$) to predict Whether a user will be active on the platform between day-$(t+28)$ and day-$(t+34)$. :\n",
    "\n",
    "- The user's total video watching time (in minutes) of the 28 days spent on the hot page (发现页);\n",
    "- The user's total video watching time (in minutes) of the 28 days spent on the follow page (关注页);\n",
    "- The user's total live watching time (in minutes) of the 28 days spent on the follow page (关注页);\n",
    "- The user's total video watching time (in minutes) of the 28 days spent on the nearby page (同城页);\n",
    "- The user's total live watching time (in minutes) of the 28 days spent on the nearby page (同城页);\n",
    "- The user's total time (in minutes) of the 28 days spent on the comment area (评论区);\n",
    "- The user's total number of comments of the 28 days posted on the comment area.\n",
    "\n",
    "We first read the data set ```Kwai_Retention.csv``` and take a look at the first few rows of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import sklearn\n",
    "import scipy as sp\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Set the random seed such that the results are replicable.\n",
    "\n",
    "random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>retention</th>\n",
       "      <th>h_video</th>\n",
       "      <th>f_video</th>\n",
       "      <th>f_live</th>\n",
       "      <th>n_video</th>\n",
       "      <th>n_live</th>\n",
       "      <th>comment_duration</th>\n",
       "      <th>comment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.333127</td>\n",
       "      <td>82.440787</td>\n",
       "      <td>50.715540</td>\n",
       "      <td>25.448967</td>\n",
       "      <td>31.928108</td>\n",
       "      <td>24.547305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>169.315973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.053897</td>\n",
       "      <td>0.873836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24.886263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.932622</td>\n",
       "      <td>55.413817</td>\n",
       "      <td>136.752137</td>\n",
       "      <td>9.372263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>180.547294</td>\n",
       "      <td>67.597604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.487704</td>\n",
       "      <td>13.855340</td>\n",
       "      <td>23.045255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>124.664241</td>\n",
       "      <td>81.037966</td>\n",
       "      <td>156.721750</td>\n",
       "      <td>37.109027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.401544</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  retention     h_video    f_video      f_live    n_video  \\\n",
       "0        1          1   14.333127  82.440787   50.715540  25.448967   \n",
       "1        2          0    0.000000   0.000000  169.315973   0.000000   \n",
       "2        3          1   24.886263   0.000000    8.932622  55.413817   \n",
       "3        4          0  180.547294  67.597604    0.000000   9.487704   \n",
       "4        5          1  124.664241  81.037966  156.721750  37.109027   \n",
       "\n",
       "       n_live  comment_duration  comment_num  \n",
       "0   31.928108         24.547305            2  \n",
       "1  100.053897          0.873836            0  \n",
       "2  136.752137          9.372263            1  \n",
       "3   13.855340         23.045255            2  \n",
       "4    0.000000         26.401544            3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwai_retention = pd.read_csv(\"Kwai_Retention.csv\")\n",
    "kwai_retention.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in this data set:\n",
    "\n",
    "- **user_id**: the user's id\n",
    "\n",
    "- **retention**: the $Y$ variable, defined as whether the user will be active between day-$(t+28)$ and day-(t+34)\n",
    "\n",
    "- **h_video**: the total time (in minutes) the user spent watching video on the hot page between day-$(t-27)$ and day-$t$\n",
    "\n",
    "- **f_video**: the total time (in minutes) the user spent watching video on the follow page between day-$(t-27)$ and day-$t$\n",
    "\n",
    "- **f_live**: the total time (in minutes) the user spent watching live streaming on the follow page between day-$(t-27)$ and day-$t$\n",
    "\n",
    "- **n_video**: the total time (in minutes) the user spent watching video on the nearby page between day-$(t-27)$ and day-$t$\n",
    "\n",
    "- **n_live**: the total time (in minutes) the user spent watching live streaming on the follow page between day-$(t-27)$ and day-$t$\n",
    "\n",
    "- **comment_duration**: the total time (in minutes) the user spent in the comment area between day-$(t-27)$ and day-$t$\n",
    "\n",
    "- **comment_num**: the total number of comments the user posted in the comment area between day-$(t-27)$ and day-$t$\n",
    "\n",
    "As before, we can do some descriptive data analysis such as summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   user_id           100000 non-null  int64  \n",
      " 1   retention         100000 non-null  int64  \n",
      " 2   h_video           100000 non-null  float64\n",
      " 3   f_video           100000 non-null  float64\n",
      " 4   f_live            100000 non-null  float64\n",
      " 5   n_video           100000 non-null  float64\n",
      " 6   n_live            100000 non-null  float64\n",
      " 7   comment_duration  100000 non-null  float64\n",
      " 8   comment_num       100000 non-null  int64  \n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "kwai_retention.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>retention</th>\n",
       "      <th>h_video</th>\n",
       "      <th>f_video</th>\n",
       "      <th>f_live</th>\n",
       "      <th>n_video</th>\n",
       "      <th>n_live</th>\n",
       "      <th>comment_duration</th>\n",
       "      <th>comment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>0.694450</td>\n",
       "      <td>104.200193</td>\n",
       "      <td>46.760036</td>\n",
       "      <td>85.452691</td>\n",
       "      <td>43.282025</td>\n",
       "      <td>38.507364</td>\n",
       "      <td>14.808549</td>\n",
       "      <td>1.309540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "      <td>0.460642</td>\n",
       "      <td>57.715839</td>\n",
       "      <td>41.380467</td>\n",
       "      <td>69.090939</td>\n",
       "      <td>45.363376</td>\n",
       "      <td>43.059011</td>\n",
       "      <td>10.987915</td>\n",
       "      <td>1.059894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25000.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.802564</td>\n",
       "      <td>7.074414</td>\n",
       "      <td>24.559063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.803831</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.025224</td>\n",
       "      <td>40.965924</td>\n",
       "      <td>78.531102</td>\n",
       "      <td>31.916939</td>\n",
       "      <td>25.226224</td>\n",
       "      <td>13.980232</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75000.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>143.429000</td>\n",
       "      <td>74.697443</td>\n",
       "      <td>132.463395</td>\n",
       "      <td>72.396484</td>\n",
       "      <td>65.310167</td>\n",
       "      <td>22.273735</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>403.051373</td>\n",
       "      <td>240.184609</td>\n",
       "      <td>444.494104</td>\n",
       "      <td>312.644168</td>\n",
       "      <td>276.276939</td>\n",
       "      <td>68.127146</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id      retention        h_video        f_video  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean    50000.500000       0.694450     104.200193      46.760036   \n",
       "std     28867.657797       0.460642      57.715839      41.380467   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%     25000.750000       0.000000      62.802564       7.074414   \n",
       "50%     50000.500000       1.000000     103.025224      40.965924   \n",
       "75%     75000.250000       1.000000     143.429000      74.697443   \n",
       "max    100000.000000       1.000000     403.051373     240.184609   \n",
       "\n",
       "              f_live        n_video         n_live  comment_duration  \\\n",
       "count  100000.000000  100000.000000  100000.000000     100000.000000   \n",
       "mean       85.452691      43.282025      38.507364         14.808549   \n",
       "std        69.090939      45.363376      43.059011         10.987915   \n",
       "min         0.000000       0.000000       0.000000          0.000000   \n",
       "25%        24.559063       0.000000       0.000000          5.803831   \n",
       "50%        78.531102      31.916939      25.226224         13.980232   \n",
       "75%       132.463395      72.396484      65.310167         22.273735   \n",
       "max       444.494104     312.644168     276.276939         68.127146   \n",
       "\n",
       "         comment_num  \n",
       "count  100000.000000  \n",
       "mean        1.309540  \n",
       "std         1.059894  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%         2.000000  \n",
       "max         6.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwai_retention.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we randomly split the data into training and validation sets by randomly sample 70% of the data into the training set and the rest into the testing set. Because of the random split, the results produced in this document may be slightly different from those reported in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tr_te_split\n",
    "X = np.array(kwai_retention.drop(columns=['retention','user_id'])).reshape(kwai_retention.shape[0],kwai_retention.shape[1]-2)\n",
    "y = kwai_retention['retention'].ravel()\n",
    "X_train, X_test, y_train, y_test = tr_te_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we standardize the features of the data points both in the training set and in the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the StandardScaler function from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We use the mean and standard deviation of the training set to standardize both the training and testing sets.\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_st = scaler.transform(X_train)\n",
    "\n",
    "X_test_st = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to measure the overall accuracy (the proportion of corrected predictions) of $k-$NN model for predicting outcomes in the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tn, fp, fn, tp):\n",
    "    return (tn+tp)/(tn+fp+fn+tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try to make predictions on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the KNeighborsClassifier function in sklearn.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Fit a kNN model on the training set.\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 5).fit(X_train_st,y_train)\n",
    "\n",
    "# Make predictions on the testing set.\n",
    "pred_ret = knn_clf.predict(X_test_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the (out-of-sample) overall accuracy and confusion for $k-$NN. The FPR, FNP, precision, recall, and specificity can all be calculated accordingly and is left as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a function to print the confusion matrix.\n",
    "def printCM(tn, fp, fn, tp):\n",
    "    print('{: <9} {: <9} {: <9}'.format(' ',' ','predicted'))\n",
    "    print('         --------------------')\n",
    "    print('{: <9}|{: <9d}|{: <9d}'.format('Actual',0,1))\n",
    "    print('-----------------------------')\n",
    "    print('{: <9d}|tn={: <6d}|fp={: <9d}'.format(0,tn,fp))\n",
    "    print('-----------------------------')\n",
    "    print('{: <9d}|fn={: <6d}|tp={: <9d}'.format(1,fn,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy of kNN classifier is 0.6798.\n",
      "\n",
      "\n",
      "                    predicted\n",
      "         --------------------\n",
      "Actual   |0        |1        \n",
      "-----------------------------\n",
      "0        |tn=3220  |fp=5932     \n",
      "-----------------------------\n",
      "1        |fn=3673  |tp=17175    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_ret).ravel()\n",
    "print('The overall accuracy of kNN classifier is {:.4f}.'.format(accuracy(tn, fp, fn, tp)))\n",
    "print('\\n')\n",
    "printCM(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the $5-$NN model produces a similar overall accuracy to the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, we can use $\\hat g(X)=\\hat P[Y=1|X]=\\frac{\\hat k_1(X)}{k}$ to estimate the conditional probability of $Y=1$ given feature $X$. With this estimate, we can define a classifier \n",
    "\n",
    "<font color=red>\n",
    "\n",
    "$$\\hat f(X_i|t):=\\begin{cases}\n",
    "1,\\mbox{ if }\\hat g(X_i)\\ge t\\\\\n",
    "0,\\mbox{ if }\\hat g(X_i)< t\n",
    "\\end{cases}$$\n",
    "\n",
    "</font>\n",
    "\n",
    "where $t\\in(0,1)$ is a threshold for predicting positive outcome. For different values of $t$, we can calculate the corresponding false-positive rates and the true-positive rates of the classifier $\\hat f(X_i|t)$ and plot the ROC curve. The AUC could then be computed immediately.\n",
    "\n",
    "We now plot the ROC curve and compute the AUC for the $k$NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve function in sklearn\n",
    "\n",
    "from sklearn.metrics import  roc_curve, auc, plot_roc_curve\n",
    "\n",
    "pred_prob = knn_clf.predict_proba(X_test_st)\n",
    "\n",
    "# The ROC function returns the false-positive rates, the false-negative rates, and the thresholds t that compute the fpr and fnr.\n",
    "fpr,tpr,thresholds = roc_curve(y_test, pred_prob[:,1])\n",
    "roc_auc =auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb74b81b940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the AUC curve\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "lw=2, label='ROC curve (AUC = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>\n",
    "# 3. Remarks for $k-$NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few remarks are in order for the $k-$NN model. First of all, the parameter $k$ essentially captures the complexity of the model. Specifically, the smaller the $k$, the more complex the model. We will discuss the implication of model complexity on prediction performance in the document on bias-variance tradeoff. The complexities of $k-$NN models with different $k$'s are illustrated in the following figure, which clearly shows the model is more complex (i.e., the border line for different labels is more zigzagged) if $k$ is smaller. Please also note that here model complexity does NOT refer to the time complexity of the algorithm. Instead, it means the complexity of the decision rule to classify the new data points with labels.\n",
    "\n",
    "<img src=\"knn-complexity.png\" width=750>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Accuracy and Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the birth of $k-$NN dates back to 1960s, it is a very powerful model in the sense that the prediction accuracy can be very high in general when the size of the training set $n$ is large. In fact, one can theoretically show that, under some reasonable assumptions about the true data generating process, the 0-1 Loss will converge to 0 as the sample size $n$ goes to infinity. A drawback of the $k-$NN model is that it is very slow with a large training data set sample size $n$. This is because the model needs to compute the distance between each data point in the training set and that in the validation set. Later in this course, we will study how to use tree-based models and heuristics to leverage the advantage of $k-$NN but with a much shorter computational time.  \n",
    "\n",
    "Linear regression and logistic regression belong to the family of parametric models ([Wiki Page](https://en.wikipedia.org/wiki/Parametric_model)), whereas $k-$NN is referred to as a non-parametric model ([Wiki Page](https://en.wikipedia.org/wiki/Nonparametric_statistics)). In statistics and machine learning, we call a model that can be captured by a finite-dimensional parameter vector a parametric model, which is the case of linear regression and logistic regression (parameterized by $(\\beta_0,\\beta_1,...,\\beta_p)$). The $k-$NN model, however, cannot be represented by a finite-dimensional parameter vector.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. $k-$NN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we remark that $k-$NN can also be used to address regression problems. Recall that, for a regression problem, the outcome $Y$ is a continuous variable. The intuition for $k-$NN regression is very similar to that for $k-$NN classification: The distance (in the feature space) reliably reflects similarities in the outcomes. The main difference between $k-$NN regression and $k-$NN classification is that, instead of taking a majority vote, $k-$NN regression predicts the outcome equal to the average outcome of its $k$ nearest neighbors in the training set. \n",
    "\n",
    "Given the training set $\\mathcal D:=\\{Y_i\\in\\mathbb R,X_{ij}:1\\le i\\le n,1\\le j \\le p\\}$, the $k-$NN model predicts the outcome $Y$ of a new datapoint with feature $X$ as follows:\n",
    "\n",
    "-------------\n",
    "\n",
    "<font color=red>\n",
    "    \n",
    "1. Compute the distance between $X$ and each data point in $\\mathcal D$: $d_i:=d(X,X_i)$ for all $i=1,2,...,n$.\n",
    "2. Find $k$ data points in $\\mathcal D$ who are closest to $X$, i.e., who have the smallest $d_i$, which we denote as $\\hat{\\mathcal D}_k(X)$.\n",
    "3. Predict the outcome using the average outcome of the $k$ data points in $\\hat{\\mathcal D}_k(X)$, i.e., \n",
    "$$\\hat Y=\\hat f(X)=\\frac{1}{k}\\sum_{i\\in \\hat{\\mathcal D}_k(X)}Y_i$$\n",
    "\n",
    "</font>\n",
    "    \n",
    "---------------\n",
    "\n",
    "In Python, we could use the module ```KNeighborsRegressor``` in the ```sklearn``` package to fit a $k-$NN regression model. See the [this Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) for more details. You may work on your own to predict the hotel room prices using the $k$NN regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  4. Concluding Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inability to handle the **non-linear relationship** between label and features motivates us build the non-parametric $k$NN model. The $k$NN model is very accurate if the distance in the feature space reliably reflects label similarity. The downside of the $k$NN model is that it suffers from the curse of dimensionality. Furthermore, the $k$NN model is computationally not quite scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
